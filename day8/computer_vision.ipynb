{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "5eVVFxTLpVGb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python in /opt/homebrew/Caskroom/miniconda/base/envs/datascience/lib/python3.11/site-packages (4.9.0.80)\n",
      "Requirement already satisfied: numpy>=1.21.2 in /opt/homebrew/Caskroom/miniconda/base/envs/datascience/lib/python3.11/site-packages (from opencv-python) (1.26.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "HUvNtKu2pVGc"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "HjRuzl8_pVGd"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ WARN:0@0.499] global loadsave.cpp:248 findDecoder imread_('input_1.jpg'): can't open/read file: check file path/integrity\n"
     ]
    },
    {
     "ename": "error",
     "evalue": "OpenCV(4.9.0) /Users/xperience/GHA-OpenCV-Python2/_work/opencv-python/opencv-python/opencv/modules/highgui/src/window.cpp:971: error: (-215:Assertion failed) size.width>0 && size.height>0 in function 'imshow'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m input_1 \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mimread(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput_1.jpg\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m cv2\u001b[38;5;241m.\u001b[39mimshow(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHello world\u001b[39m\u001b[38;5;124m\"\u001b[39m,input_1)\n\u001b[1;32m      3\u001b[0m cv2\u001b[38;5;241m.\u001b[39mwaitKey()\n\u001b[1;32m      4\u001b[0m cv2\u001b[38;5;241m.\u001b[39mdestroyAllWindows()\n",
      "\u001b[0;31merror\u001b[0m: OpenCV(4.9.0) /Users/xperience/GHA-OpenCV-Python2/_work/opencv-python/opencv-python/opencv/modules/highgui/src/window.cpp:971: error: (-215:Assertion failed) size.width>0 && size.height>0 in function 'imshow'\n"
     ]
    }
   ],
   "source": [
    "input_1 = cv2.imread(\"input_1.jpg\")\n",
    "cv2.imshow(\"Hello world\",input_1)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "Bh72eu4CpVGd",
    "outputId": "499fda21-76e1-4972-cd7c-5d63d295464e"
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mHeiht of image\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28mint\u001b[39m(input_1\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]),\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpixels\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mWidth of image\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28mint\u001b[39m(input_1\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]),\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpixels\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "print ('Heiht of image', int(input_1.shape[0]),'pixels')\n",
    "print ('Width of image', int(input_1.shape[1]),'pixels')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HSGIkx0YpVGe",
    "outputId": "849843dd-8e5d-4e00-ed2c-f514bb0dc43d"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "checkBoard = np.zeros((9,9))\n",
    "checkBoard[0::2,1::2]=1\n",
    "checkBoard[1::2,0::2]=1\n",
    "print(checkBoard)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "54qCG1WkpVGf"
   },
   "outputs": [],
   "source": [
    "import matplotlib.image as mpig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b5HSW1r3pVGf",
    "outputId": "e69131f8-2a60-49de-8657-8de464a51ee2"
   },
   "outputs": [],
   "source": [
    "plt.imshow(checkBoard,cmap=\"gray\",interpolation=\"nearest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "sNP5_ZETpVGf",
    "outputId": "f93637b1-f5c8-46a3-cfb9-15ec12e19d05"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.28888887 0.32941177 0.38039216 0.50326794 0.47973856 0.50457519\n",
      "  0.55947715 0.54901963 0.56732029 0.57516342 0.59738559 0.61307186\n",
      "  0.59607846 0.56078434 0.54248363 0.49281046 0.45359477 0.44183007\n",
      "  0.2522876  0.23529412 0.4261438  0.49673203 0.72418302 0.69934636\n",
      "  0.43529412]\n",
      " [0.29411766 0.33333334 0.44052288 0.52026147 0.49934641 0.53464049\n",
      "  0.55424833 0.59869283 0.6156863  0.61960787 0.620915   0.63660127\n",
      "  0.62875813 0.6326797  0.59215689 0.52418303 0.47581699 0.44705883\n",
      "  0.34640524 0.32287583 0.33202612 0.59738559 0.81830066 0.77777773\n",
      "  0.27843139]\n",
      " [0.35294119 0.41568628 0.42745098 0.48104575 0.50457519 0.52287579\n",
      "  0.53594774 0.63529414 0.65359479 0.620915   0.61830068 0.64444441\n",
      "  0.61830068 0.61830068 0.60000002 0.53856206 0.46405229 0.43137255\n",
      "  0.37254903 0.37908494 0.29411766 0.50065356 0.60915029 0.53856206\n",
      "  0.36732024]\n",
      " [0.41176471 0.43006536 0.49542484 0.48627451 0.50980395 0.52679735\n",
      "  0.53071892 0.60915029 0.57516342 0.59869283 0.63006538 0.64705884\n",
      "  0.63921571 0.63398695 0.59738559 0.54248363 0.46013072 0.41699347\n",
      "  0.39607844 0.30718955 0.26274511 0.48627451 0.26143789 0.1856209\n",
      "  0.19477125]\n",
      " [0.43137255 0.49673203 0.47712418 0.46797386 0.48627451 0.53071892\n",
      "  0.5411765  0.60130715 0.63660127 0.61830068 0.59869283 0.61437911\n",
      "  0.63006538 0.61699343 0.5581699  0.5281046  0.47973856 0.45228758\n",
      "  0.4130719  0.3594771  0.23921569 0.36993465 0.1856209  0.16732027\n",
      "  0.19084968]\n",
      " [0.48104575 0.47320262 0.39869279 0.43921569 0.47973856 0.54248363\n",
      "  0.55032676 0.58954245 0.62614381 0.61960787 0.61960787 0.62222224\n",
      "  0.63137257 0.620915   0.57908499 0.54771245 0.49542484 0.43137255\n",
      "  0.44052288 0.27712417 0.22222222 0.41437906 0.1751634  0.1751634\n",
      "  0.19084968]\n",
      " [0.42483661 0.42222223 0.35816994 0.46797386 0.50326794 0.51503265\n",
      "  0.43529412 0.49019608 0.53725493 0.49803922 0.47189543 0.55947715\n",
      "  0.56209147 0.55424833 0.42091504 0.36862746 0.28627452 0.29934642\n",
      "  0.34640524 0.28627452 0.32549021 0.31895426 0.18431373 0.18431373\n",
      "  0.20261438]\n",
      " [0.36862746 0.31764707 0.4627451  0.49803922 0.48235294 0.4379085\n",
      "  0.43921569 0.38039216 0.3019608  0.31111112 0.40915033 0.44836602\n",
      "  0.49542484 0.47189543 0.33725491 0.28104573 0.41437906 0.41437906\n",
      "  0.35032681 0.43267974 0.37385622 0.31764707 0.17908497 0.19869281\n",
      "  0.19869281]\n",
      " [0.20784314 0.29411766 0.50718951 0.48104575 0.47450981 0.45228758\n",
      "  0.47189543 0.42745098 0.28235295 0.27189544 0.28888887 0.45751634\n",
      "  0.61045754 0.34509805 0.25098041 0.17908497 0.16078432 0.2\n",
      "  0.43006536 0.47712418 0.29934642 0.59346402 0.41568628 0.31503269\n",
      "  0.1738562 ]\n",
      " [0.26274511 0.27973858 0.46928105 0.50718951 0.56601304 0.49803922\n",
      "  0.4509804  0.55163401 0.31111112 0.52287579 0.52549022 0.52026147\n",
      "  0.59346402 0.42091504 0.43921569 0.50065356 0.46535948 0.5281046\n",
      "  0.47320262 0.45228758 0.21699347 0.81045753 0.74640518 0.35424837\n",
      "  0.15294118]\n",
      " [0.30326799 0.4130719  0.45882353 0.50588238 0.58562088 0.57124186\n",
      "  0.57516342 0.59607846 0.53986931 0.5411765  0.58300656 0.48366013\n",
      "  0.55555558 0.44444445 0.47320262 0.52026147 0.52026147 0.49019608\n",
      "  0.53856206 0.47058824 0.41045749 0.80130714 0.71241832 0.33464053\n",
      "  0.1633987 ]\n",
      " [0.42091504 0.40522876 0.43529412 0.49150327 0.55555558 0.60130715\n",
      "  0.61045754 0.63006538 0.61176473 0.65620911 0.5281046  0.53333336\n",
      "  0.56601304 0.48496732 0.46143791 0.5281046  0.56601304 0.55555558\n",
      "  0.48235294 0.43921569 0.47581699 0.50326794 0.35555553 0.28888887\n",
      "  0.20130718]\n",
      " [0.53725493 0.43137255 0.4627451  0.47843137 0.50065356 0.57124186\n",
      "  0.64444441 0.627451   0.64836597 0.64052284 0.50457519 0.5411765\n",
      "  0.63660127 0.55555558 0.44967321 0.48496732 0.61437911 0.55686277\n",
      "  0.44183007 0.42091504 0.42483661 0.19738561 0.21568628 0.22875817\n",
      "  0.22875817]\n",
      " [0.42483661 0.44313726 0.44444445 0.45620915 0.49019608 0.50588238\n",
      "  0.57908499 0.60130715 0.6026144  0.53071892 0.54509807 0.55163401\n",
      "  0.56078434 0.61176473 0.43398693 0.41437906 0.48235294 0.49803922\n",
      "  0.42091504 0.41045749 0.38954249 0.19084968 0.21960784 0.22614379\n",
      "  0.23529412]\n",
      " [0.46797386 0.43529412 0.45228758 0.46797386 0.50457519 0.4875817\n",
      "  0.52026147 0.53594774 0.50196081 0.47320262 0.39477122 0.29803923\n",
      "  0.49411765 0.49281046 0.26797387 0.40784314 0.38039216 0.44705883\n",
      "  0.38954249 0.39869279 0.20261438 0.18300654 0.20915033 0.22875817\n",
      "  0.23529412]\n",
      " [0.4261438  0.39607844 0.44575164 0.46143791 0.51241833 0.47450981\n",
      "  0.49019608 0.49673203 0.4509804  0.5581699  0.58039218 0.54901963\n",
      "  0.40653592 0.40261436 0.41960785 0.4261438  0.35686275 0.3764706\n",
      "  0.37516338 0.4130719  0.1751634  0.17777777 0.2130719  0.21699347\n",
      "  0.23137255]\n",
      " [0.37124181 0.37516338 0.41437906 0.44705883 0.49673203 0.49019608\n",
      "  0.50326794 0.51503265 0.50718951 0.50980395 0.58562088 0.60392159\n",
      "  0.55032676 0.55163401 0.47320262 0.41045749 0.37254903 0.4013072\n",
      "  0.4130719  0.36732024 0.4130719  0.30718955 0.18692811 0.30849671\n",
      "  0.22614379]\n",
      " [0.13986929 0.08888888 0.38562092 0.44183007 0.46535948 0.52287579\n",
      "  0.53594774 0.50588238 0.48104575 0.46928105 0.49019608 0.54771245\n",
      "  0.53725493 0.54901963 0.46666667 0.39084965 0.3764706  0.4261438\n",
      "  0.37908494 0.20392157 0.08627451 0.09019608 0.1124183  0.0627451\n",
      "  0.22745098]\n",
      " [0.10980392 0.09934641 0.32810456 0.41960785 0.4627451  0.50065356\n",
      "  0.5464052  0.50326794 0.48104575 0.36601308 0.16470589 0.09019608\n",
      "  0.11503268 0.10980392 0.06535947 0.2496732  0.41960785 0.43398693\n",
      "  0.37908494 0.08627451 0.09281045 0.06797386 0.075817   0.03660131\n",
      "  0.06797386]\n",
      " [0.09673202 0.44313726 0.49934641 0.40000001 0.46535948 0.47581699\n",
      "  0.51111108 0.53333336 0.4875817  0.15163399 0.13202615 0.16732027\n",
      "  0.21437909 0.21176471 0.16601306 0.32287583 0.39477122 0.43529412\n",
      "  0.37777779 0.09019608 0.07843138 0.0875817  0.06797386 0.04836601\n",
      "  0.075817  ]\n",
      " [0.10588235 0.44967321 0.67843139 0.35686275 0.41437906 0.42745098\n",
      "  0.49542484 0.49542484 0.52026147 0.56862748 0.56862748 0.44967321\n",
      "  0.44183007 0.52418303 0.43137255 0.40784314 0.49934641 0.40522876\n",
      "  0.15163399 0.10196079 0.07189543 0.06797386 0.07189543 0.06013072\n",
      "  0.07189543]\n",
      " [0.10326798 0.26013073 0.84444445 0.37385622 0.37124181 0.41176471\n",
      "  0.46797386 0.5411765  0.54509807 0.51895422 0.5281046  0.55163401\n",
      "  0.53986931 0.55163401 0.41176471 0.41437906 0.47712418 0.35816994\n",
      "  0.07712418 0.0875817  0.07843138 0.06013072 0.07189543 0.07189543\n",
      "  0.06797386]\n",
      " [0.10980392 0.10588235 0.80653596 0.77516341 0.36732024 0.39346406\n",
      "  0.42222223 0.53202617 0.57908499 0.52156866 0.47973856 0.44444445\n",
      "  0.39477122 0.38954249 0.35816994 0.42745098 0.43137255 0.14509805\n",
      "  0.08366013 0.08627451 0.075817   0.06013072 0.05620915 0.07189543\n",
      "  0.075817  ]\n",
      " [0.10588235 0.11372549 0.81307185 0.80000001 0.7647059  0.38039216\n",
      "  0.39215687 0.46405229 0.58300656 0.56732029 0.53986931 0.50849676\n",
      "  0.49673203 0.46143791 0.42745098 0.48235294 0.30980393 0.0875817\n",
      "  0.07320261 0.08366013 0.0875817  0.06405229 0.04444444 0.06013072\n",
      "  0.07189543]\n",
      " [0.09150327 0.0875817  0.66405225 0.84052289 0.8143791  0.82222223\n",
      "  0.37777779 0.36862746 0.52679735 0.60130715 0.59477127 0.57385617\n",
      "  0.55686277 0.54248363 0.51764709 0.45620915 0.16732027 0.08235294\n",
      "  0.07058824 0.06797386 0.07450981 0.06013072 0.05620915 0.06405229\n",
      "  0.06797386]]\n"
     ]
    }
   ],
   "source": [
    "from skimage import data\n",
    "image_of_a_bush = data.lfw_subset()\n",
    "image_of_a_bush = image_of_a_bush[0,:,:]\n",
    "print(image_of_a_bush)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "_ZO6hIuvpVGg",
    "outputId": "be06ed26-75ca-4c83-8a82-e8f6d1a3e684"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m3\u001b[39m,\u001b[38;5;241m3\u001b[39m))\n\u001b[1;32m      2\u001b[0m plt\u001b[38;5;241m.\u001b[39mimshow(image_of_a_bush,cmap\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgray\u001b[39m\u001b[38;5;124m\"\u001b[39m,interpolation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnearest\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      3\u001b[0m plt\u001b[38;5;241m.\u001b[39mshow()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "plt.figure(figsize=(3,3))\n",
    "plt.imshow(image_of_a_bush,cmap=\"gray\",interpolation=\"nearest\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "66WXO4G2pVGg",
    "outputId": "004d5e55-f2ec-4764-997f-a1df952d8ffc"
   },
   "outputs": [],
   "source": [
    "image = data.astronaut()\n",
    "plt.imshow(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nx-jMk6EpVGh"
   },
   "outputs": [],
   "source": [
    "image = cv2.imread(\"input_1.jpg\")\n",
    "cv2.imshow(\"Original\",image)\n",
    "cv2.waitKey()\n",
    "\n",
    "gray_image= cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)\n",
    "cv2.imshow(\"Grayscale\",gray_image)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CxUEaEZupVGh"
   },
   "outputs": [],
   "source": [
    "img = cv2.imread(\"input_1.jpg\",0)\n",
    "cv2.imshow(\"Grayscale\",img)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "U5DE2iqFpVGh",
    "outputId": "db60374b-6b9a-4575-805d-61cea13889da"
   },
   "outputs": [],
   "source": [
    "image = cv2.imread(\"input.jpg\")\n",
    "B,G,R = image[0,0]\n",
    "B,G,R = image[10,50]\n",
    "print(B,G,R)\n",
    "print(image.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jGJDcBkupVGi",
    "outputId": "9452ee4d-f985-4a77-ccad-90ae7e67718f"
   },
   "outputs": [],
   "source": [
    "gray_img = cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)\n",
    "print(gray_img.shape)\n",
    "print(gray_img[10,50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1lWvnhvzpVGi",
    "outputId": "0b356b3b-0989-49e9-c627-d86c5258712d"
   },
   "outputs": [],
   "source": [
    "gray_img[0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "spdthWb0pVGi"
   },
   "outputs": [],
   "source": [
    "image = cv2.imread(\"input.jpg\")\n",
    "hsv_image = cv2.cvtColor(image,cv2.COLOR_BGR2HSV)\n",
    "\n",
    "cv2.imshow(\"HSV image\",hsv_image[:,:,:])\n",
    "cv2.imshow(\"Hue channel\",hsv_image[:,:,0])\n",
    "cv2.imshow(\"Saturation channel\",hsv_image[:,:,1])\n",
    "cv2.imshow(\"Calue channel\",hsv_image[:,:,2])\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EJUOMHEOpVGi",
    "outputId": "52e1736b-f406-4cde-f32c-be5c8f07c579"
   },
   "outputs": [],
   "source": [
    "image = cv2.imread(\"input_1.jpg\")\n",
    "B,G,R =cv2.split(image)\n",
    "print(B.shape)\n",
    "cv2.imshow(\"Red\",R)\n",
    "cv2.imshow(\"Green\",G)\n",
    "cv2.imshow(\"Blue\",B)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "merged = cv2.merge([B,G,R])\n",
    "cv2.imshow(\"Merged\",merged)\n",
    "merged= cv2.merge([B+100,G,R+100])\n",
    "cv2.imshow(\"Merged with Blue Amplified\",merged)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1XcQvJ1DpVGi"
   },
   "outputs": [],
   "source": [
    "image = cv2.imread('input.jpg')\n",
    "\n",
    "height,width = image.shape[:2]\n",
    "\n",
    "quareter_height,quareter_width = height/4,width/4\n",
    "\n",
    "T = np.float32([[1,0,quareter_width],[0,1,quareter_height]])\n",
    "\n",
    "img_translation = cv2.warpAffine(image,T,(width,height))\n",
    "cv2.imshow('Translation',img_translation)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_JtZgEoDpVGj"
   },
   "outputs": [],
   "source": [
    "image = cv2.imread('input.jpg')\n",
    "\n",
    "height,width = image.shape[:2]\n",
    "\n",
    "rotation_matrix = cv2.getRotationMatrix2D((width/2,height/2),45,.5)\n",
    "\n",
    "rotated_image = cv2.warpAffine(image,rotation_matrix,(width,height))\n",
    "\n",
    "cv2.imshow('Rotated Image',rotated_image)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wkc8sfQopVGj"
   },
   "outputs": [],
   "source": [
    "image = cv2.imread('input_1.jpg',0)\n",
    "\n",
    "height,width = image.shape[:2]\n",
    "\n",
    "sobel_x = cv2.Sobel(image,cv2.CV_64F,0,1,ksize = 5)\n",
    "sobel_y = cv2.Sobel(image,cv2.CV_64F,1,0,ksize = 5)\n",
    "\n",
    "cv2.imshow('Rotated Image',image)\n",
    "cv2.waitKey(0)\n",
    "cv2.imshow('Sobel X',sobel_x)\n",
    "cv2.waitKey(0)\n",
    "cv2.imshow('Sobel Y',sobel_y)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "sobel_OR = cv2.bitwise_or(sobel_x,sobel_y)\n",
    "cv2.imshow('sobel_OR',sobel_OR)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "laplacian = cv2.Laplacian(image,cv2.CV_64F)\n",
    "cv2.imshow('Laplacian',laplacian)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "canny = cv2.Canny(image,50,120)\n",
    "cv2.imshow('Canny',canny)\n",
    "cv2.waitKey(0)\n",
    " \n",
    "\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0-IbFQdKpVGj",
    "outputId": "00b5bd8f-c326-4c53-8317-59a3ebae7b45"
   },
   "outputs": [],
   "source": [
    "def sketch(image):\n",
    "    img_gray = cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    img_gray_blur = cv2.GaussianBlur(img_gray,(5,5),0)\n",
    "    canny_edges = cv2.Canny(img_gray_blur,10,70)\n",
    "    ret,mask = cv2.threshold(canny_edges,250,255,cv2.THRESH_BINARY_INV)\n",
    "    return mask\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    ret,frame = cap.read()\n",
    "    cv2.imshow('Our live Sketcher',sketch(frame))\n",
    "    if cv2.waitKey(1) == 13:\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "print('done')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MFVCDZQfpVGk"
   },
   "outputs": [],
   "source": [
    "image = cv2.imread(\"WaldoBeach.jpg\")\n",
    "\n",
    "cv2.imshow(\"Where is Waldo\",image)\n",
    "cv2.waitKey(0)\n",
    "gray = cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "template = cv2.imread(\"waldo.jpg\",0)\n",
    "\n",
    "result = cv2.matchTemplate(gray,template,cv2.TM_CCOEFF)\n",
    "minVal,maxVal,minLoc,maxLoc = cv2.minMaxLoc(result)\n",
    "\n",
    "top_left = maxLoc\n",
    "bottom_right =(top_left[0] + 50, top_left[1]+50)\n",
    "cv2.rectangle(image,top_left,bottom_right,(0,0,255),5)\n",
    "\n",
    "cv2.imshow(\"Where is Waldo\",image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "i8kjuqaXpVGk",
    "outputId": "351bfa5e-b9f3-4665-a999-cebc0d240095"
   },
   "outputs": [],
   "source": [
    "plt.imshow(template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "B-S7xojNpVGk"
   },
   "outputs": [],
   "source": [
    "import imutils \n",
    "image = cv2.imread(\"input_1.jpg\")\n",
    "cv2.imshow(\"Original\",image)\n",
    "\n",
    "flipped = cv2.flip(image,0)\n",
    "cv2.imshow(\"Vertical Flip\",flipped)\n",
    "\n",
    "flipped = cv2.flip(image,1)\n",
    "cv2.imshow(\"Horizontal Flip\",flipped)\n",
    "\n",
    "flipped = cv2.flip(image,-1)\n",
    "cv2.imshow(\"Bot Flip\",flipped)\n",
    "\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4AJo20JmpVGk"
   },
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(\"airplanes.mp4\")\n",
    "\n",
    "while True:\n",
    "    ret,frame= cap.read()\n",
    "    if ret:\n",
    "        cv2.imshow(\"Demo\",frame)\n",
    "    else:\n",
    "        break\n",
    "    key = cv2.waitKey(10)\n",
    "    if key == ord(\"q\"):\n",
    "        break\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qeOMBFaJpVGk"
   },
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    ret,frame= cap.read()\n",
    "    if ret:\n",
    "        cv2.imshow(\"Bendeniz\",frame)\n",
    "    else:\n",
    "        break\n",
    "    key = cv2.waitKey(1)\n",
    "    if key == ord(\"q\"):\n",
    "        break\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WQe_kvw2pVGk"
   },
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "ret1,frame1 = cap.read()\n",
    "ret2,frame2 = cap.read()\n",
    "\n",
    "while True:\n",
    "    frame1_gray = cv2.cvtColor(frame1,cv2.COLOR_BGR2GRAY)\n",
    "    frame2_gray = cv2.cvtColor(frame2,cv2.COLOR_BGR2GRAY)\n",
    "    frame1_blur = cv2.GaussianBlur(frame1_gray,(21,21),0)\n",
    "    frame2_blur = cv2.GaussianBlur(frame2_gray,(21,21),0)\n",
    "    \n",
    "    diff = cv2.absdiff(frame1_blur,frame2_blur)\n",
    "    cv2.imshow(\"Motion\",diff)\n",
    "    frame1 = frame2\n",
    "    ret,frame2 = cap.read()\n",
    "    if not ret:\n",
    "        cap.release()\n",
    "        break\n",
    "    key = cv2.waitKey(10)\n",
    "    if key == ord(\"q\"):\n",
    "        cap.release()\n",
    "        break\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OGc9tGiApVGl"
   },
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(\"cars.mp4\")\n",
    "\n",
    "ret1,frame1 = cap.read()\n",
    "ret2,frame2 = cap.read()\n",
    "\n",
    "while True:\n",
    "    frame1_gray = cv2.cvtColor(frame1,cv2.COLOR_BGR2GRAY)\n",
    "    frame2_gray = cv2.cvtColor(frame2,cv2.COLOR_BGR2GRAY)\n",
    "    frame1_blur = cv2.GaussianBlur(frame1_gray,(21,21),0)\n",
    "    frame2_blur = cv2.GaussianBlur(frame2_gray,(21,21),0)\n",
    "    \n",
    "    diff = cv2.absdiff(frame1_blur,frame2_blur)\n",
    "    cv2.imshow(\"Motion\",diff)\n",
    "    frame1 = frame2\n",
    "    ret,frame2 = cap.read()\n",
    "    if not ret:\n",
    "        cap.release()\n",
    "        break\n",
    "    key = cv2.waitKey(10)\n",
    "    if key == ord(\"q\"):\n",
    "        cap.release()\n",
    "        break\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1pVos3M0pVGl"
   },
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(\"airplanes.mp4\")\n",
    "\n",
    "ret1,frame1 = cap.read()\n",
    "ret2,frame2 = cap.read()\n",
    "\n",
    "while True:\n",
    "    frame1_gray = cv2.cvtColor(frame1,cv2.COLOR_BGR2GRAY)\n",
    "    frame2_gray = cv2.cvtColor(frame2,cv2.COLOR_BGR2GRAY)\n",
    "    frame1_blur = cv2.GaussianBlur(frame1_gray,(21,21),0)\n",
    "    frame2_blur = cv2.GaussianBlur(frame2_gray,(21,21),0)\n",
    "    \n",
    "    diff = cv2.absdiff(frame1_blur,frame2_blur)\n",
    "    cv2.imshow(\"Motion\",diff)\n",
    "    frame1 = frame2\n",
    "    ret,frame2 = cap.read()\n",
    "    if not ret:\n",
    "        cap.release()\n",
    "        break\n",
    "    key = cv2.waitKey(10)\n",
    "    if key == ord(\"q\"):\n",
    "        cap.release()\n",
    "        break\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "z8lAUuLDpVGl"
   },
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(\"airplanes.mp4\")\n",
    "\n",
    "ret1,frame1 = cap.read()\n",
    "ret2,frame2 = cap.read()\n",
    "\n",
    "while True:\n",
    "    frame1_gray = cv2.cvtColor(frame1,cv2.COLOR_BGR2GRAY)\n",
    "    frame2_gray = cv2.cvtColor(frame2,cv2.COLOR_BGR2GRAY)\n",
    "    frame1_blur = cv2.GaussianBlur(frame1_gray,(21,21),0)\n",
    "    frame2_blur = cv2.GaussianBlur(frame2_gray,(21,21),0)\n",
    "    \n",
    "    diff = cv2.absdiff(frame1_blur,frame2_blur)\n",
    "    \n",
    "    thresh = cv2.threshold(diff,20,255,cv2.THRESH_BINARY)[1]\n",
    "    final = cv2.dilate(thresh,None,iterations=2)\n",
    "    \n",
    "    masked = cv2.bitwise_and(frame1,frame1,mask=thresh)\n",
    "    white_pixels = np.sum(thresh) /255\n",
    "    \n",
    "    rows,cols = thresh.shape\n",
    "    total= rows*cols\n",
    "    if white_pixels > 0.01*total:\n",
    "        font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "        cv2.putText(frame1,\"Movement Detected - Hareket Var\",(10,50),font,1,(0,0,255),2,cv2.LINE_AA)\n",
    "    cv2.imshow(\"Motion\",frame1)\n",
    "    frame1=frame2\n",
    "    ret,frame2 = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    key = cv2.waitKey(10)\n",
    "    if key == 27 or key == ord(\"q\"):\n",
    "        break\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zlPQreyTpVGl",
    "outputId": "bfa57b7f-f2ff-425f-9be4-4dddf72228a9"
   },
   "outputs": [],
   "source": [
    "image = cv2.imread(\"bunchofshapes.jpg\")\n",
    "cv2.imshow(\"Input Image\",image)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "gray = cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "edged = cv2.Canny(gray,30,200)\n",
    "cv2.imshow(\"Canny Edges\",edged)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "contours,hierarchy = cv2.findContours(edged,cv2.RETR_EXTERNAL,cv2.CHAIN_APPROX_NONE)\n",
    "cv2.imshow(\"Canny Edges After Contouring\",edged)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "print(\"Number of Contours found = \" + str(len(contours)))\n",
    "\n",
    "cv2.drawContours(image,contours,-1,(0,255,0),thickness=2)\n",
    "\n",
    "cv2.imshow(\"Contours\",image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZTMU12WMpVGl",
    "outputId": "e7caba2c-5ac2-4ce7-8b8e-1ebf8154427f"
   },
   "outputs": [],
   "source": [
    "plt.imshow(cv2.imread(\"bunchofshapes.jpg\",0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dtlsFOWFpVGm"
   },
   "outputs": [],
   "source": [
    "image = cv2.imread('soduku.jpg')\n",
    "cv2.imshow('Original', image)\n",
    "cv2.waitKey(0)\n",
    "# Grayscale and Canny Edges extracted\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "edges = cv2.Canny(gray, 100, 170, apertureSize = 3)\n",
    "\n",
    "# Run HoughLines using a rho accuracy of 1 pixel\n",
    "# theta accuracy of np.pi / 180 which is 1 degree\n",
    "# Our line threshold is set to 240 (number of points on line)\n",
    "lines = cv2.HoughLines(edges, 1, np.pi / 180, 240)\n",
    "\n",
    "# We iterate through each line and convert it to the format\n",
    "# required by cv2.lines (i.e. requiring end points)\n",
    "for line in lines:\n",
    "    rho, theta = line[0]\n",
    "    a = np.cos(theta)\n",
    "    b = np.sin(theta)\n",
    "    x0 = a * rho\n",
    "    y0 = b * rho\n",
    "    x1 = int(x0 + 1000 * (-b))\n",
    "    y1 = int(y0 + 1000 * (a))\n",
    "    x2 = int(x0 - 1000 * (-b))\n",
    "    y2 = int(y0 - 1000 * (a))\n",
    "    cv2.line(image, (x1, y1), (x2, y2), (255, 0, 0), 2)\n",
    "\n",
    "cv2.imshow('Hough Lines', image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NB2hvPeNpVGm"
   },
   "outputs": [],
   "source": [
    "image = cv2.imread('opencv.jpg')\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "blur = cv2.medianBlur(gray, 5)\n",
    "\n",
    "circles = cv2.HoughCircles(blur, cv2.HOUGH_GRADIENT, 1.5, 20)\n",
    "\n",
    "circles = np.uint16(np.around(circles))\n",
    "\n",
    "for i in circles[0,:]:\n",
    "    # draw the outer circle\n",
    "    cv2.circle(image,(i[0], i[1]), i[2], (0, 255, 0), 2)\n",
    "    \n",
    "    # draw the center of the circle\n",
    "    cv2.circle(image, (i[0], i[1]), 2, (0, 255, 0), 5)\n",
    "\n",
    "cv2.imshow('detected circles', image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WpSJmpxApVGm"
   },
   "outputs": [],
   "source": [
    "# Read image\n",
    "image = cv2.imread(\"Sunflowers.jpg\")\n",
    " \n",
    "# Set up the detector with default par ameters.\n",
    "detector =cv2.SimpleBlobDetector_create()\n",
    " \n",
    "# Detect blobs.\n",
    "keypoints = detector.detect(image) \n",
    " \n",
    "# Draw detected blobs as red circles.\n",
    "# cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS ensures the size of\n",
    "# the circle corresponds to the size of blob\n",
    "blank = np.zeros((1,1)) \n",
    "blobs = cv2.drawKeypoints(image, keypoints, blank, (255,0,0),\n",
    "                                      cv2.DRAW_MATCHES_FLAGS_DEFAULT)\n",
    " \n",
    "# Show keypoints\n",
    "cv2.imshow(\"Blobs\", blobs)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PzBZINgvpVGn"
   },
   "outputs": [],
   "source": [
    "# Read image\n",
    "image = cv2.imread(\"Sunflowers.jpg\")\n",
    " \n",
    "# Set up the detector with default par ameters.\n",
    "detector =cv2.SimpleBlobDetector_create()\n",
    " \n",
    "# Detect blobs.\n",
    "keypoints = detector.detect(image) \n",
    " \n",
    "# Draw detected blobs as red circles.\n",
    "# cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS ensures the size of\n",
    "# the circle corresponds to the size of blob\n",
    "blank = np.zeros((1,1)) \n",
    "blobs = cv2.drawKeypoints(image, keypoints, blank, (255,0,0),\n",
    "                                      cv2.DRAW_MATCHES_FLAGS_DEFAULT)\n",
    " \n",
    "# Show keypoints\n",
    "cv2.imshow(\"Blobs\", blobs)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "660ZBSGQpVGn",
    "outputId": "589b1696-9fa1-46ad-cb49-1daf4e197e62"
   },
   "outputs": [],
   "source": [
    "\n",
    "# classifier (XML file format) is stored\n",
    "face_classifier = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "\n",
    "# Load our image then convert it to grayscale\n",
    "image = cv2.imread('myself.jpg')\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Our classifier returns the ROI of the detected face as a tuple\n",
    "# It stores the top left coordinate and the bottom right coordiantes\n",
    "faces = face_classifier.detectMultiScale(gray, 1.3, 5)\n",
    "\n",
    "# When no faces detected, face_classifier returns and empty tuple\n",
    "if faces is ():\n",
    "    print(\"No faces found\")\n",
    "\n",
    "# We iterate through our faces array and draw a rectangle\n",
    "# over each face in faces\n",
    "for (x,y,w,h) in faces:\n",
    "    cv2.rectangle(image, (x,y), (x+w,y+h), (127,0,255), 2)\n",
    "    cv2.imshow('Face Detection', image)\n",
    "    cv2.waitKey(0)\n",
    "    \n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rtomYqnxpVGn",
    "outputId": "a348ce99-6ff7-48ba-efdb-9822214945e7"
   },
   "outputs": [],
   "source": [
    "face_classifier = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "eye_classifier = cv2.CascadeClassifier('haarcascade_eye.xml')\n",
    " \n",
    "img = cv2.imread('myself.jpg')\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "faces = face_classifier.detectMultiScale(gray, 1.3, 5)\n",
    "\n",
    "# When no faces detected, face_classifier returns and empty tuple\n",
    "if faces is ():\n",
    "    print(\"No Face Found\")\n",
    "\n",
    "for (x,y,w,h) in faces:\n",
    "    cv2.rectangle(img,(x,y),(x+w,y+h),(127,0,255),2)\n",
    "    cv2.imshow('img',img)\n",
    "    cv2.waitKey(0)\n",
    "    roi_gray = gray[y:y+h, x:x+w]\n",
    "    roi_color = img[y:y+h, x:x+w]\n",
    "    eyes = eye_classifier.detectMultiScale(roi_gray)\n",
    "    for (ex,ey,ew,eh) in eyes:\n",
    "        cv2.rectangle(roi_color,(ex,ey),(ex+ew,ey+eh),(255,255,0),2)\n",
    "        cv2.imshow('img',img)\n",
    "        cv2.waitKey(0)\n",
    "    \n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bgvwxQDfpVGn",
    "outputId": "112623a4-b6ef-4a7c-cda0-83b539582d8f"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from time import sleep\n",
    "face_classifier = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "eye_classifier = cv2.CascadeClassifier('haarcascade_eye.xml')\n",
    "def face_detector(img, size=0.5):\n",
    "    # Convert image to grayscale\n",
    "    gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_classifier.detectMultiScale(gray, 1.3, 5)\n",
    "    if faces is ():\n",
    "        return img\n",
    "    for (x,y,w,h) in faces:\n",
    "        x = x - 50\n",
    "        w = w + 50\n",
    "        y = y - 50\n",
    "        h = h + 50\n",
    "        cv2.rectangle(img,(x,y),(x+w,y+h),(255,0,0),2)\n",
    "        roi_gray = gray[y:y+h, x:x+w]\n",
    "        roi_color = img[y:y+h, x:x+w]\n",
    "        eyes = eye_classifier.detectMultiScale(roi_gray)\n",
    "        sleep(.05)\n",
    "        for (ex,ey,ew,eh) in eyes:\n",
    "            cv2.rectangle(roi_color,(ex,ey),(ex+ew,ey+eh),(0,0,255),2)\n",
    "    img = cv2.flip(img,1)\n",
    "    return img\n",
    "cap = cv2.VideoCapture(0)\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    cv2.imshow('Our Face Extractor', face_detector(frame))\n",
    "    if cv2.waitKey(1) == 13: #13 is the Enter Key\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wMqW0ro-pVGn",
    "outputId": "29ad698d-82b8-438e-fc58-a21f1317c413"
   },
   "outputs": [],
   "source": [
    "#pip install opencv-contrib-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MQZYruJrpVGo",
    "outputId": "dc80359a-0731-44c6-868f-66fd98fd1554"
   },
   "outputs": [],
   "source": [
    "face_classifier = cv2.CascadeClassifier(\"haarcascade_frontalface_default.xml\")\n",
    "def face_extractor(img):\n",
    "    gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_classifier.detectMultiScale(gray,1.3,5)\n",
    "    if faces is ():\n",
    "        return None\n",
    "    for (x,y,w,h) in faces:\n",
    "        cropped_face = img[y:y+h,x:x+w]\n",
    "    return cropped_face\n",
    "cap = cv2.VideoCapture(0)\n",
    "count = 0\n",
    "while True:\n",
    "    ret,frame = cap.read()\n",
    "    if face_extractor(frame) is not None:\n",
    "        count += 1\n",
    "        face = cv2.resize(face_extractor(frame),(200,200))\n",
    "        face = cv2.cvtColor(face,cv2.COLOR_BGR2GRAY)\n",
    "        file_name_path = './faces/user/' + str(count) +'.jpg'\n",
    "        cv2.imwrite(file_name_path,face)\n",
    "        cv2.putText(face,str(count),(50,50),cv2.FONT_HERSHEY_COMPLEX,1,(0,255,0),2)\n",
    "        cv2.imshow(\"Face Cropper\",face)\n",
    "    else:\n",
    "        print(\"Face not found\")\n",
    "        pass\n",
    "    if cv2.waitKey(1) == 13 or count ==100:\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "print('Collecting Samples Complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "avTpmEk0pVGo",
    "outputId": "c04e2241-fcd6-48a2-b495-51c239a94b1c"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from os import listdir\n",
    "from os.path import isfile,join\n",
    "\n",
    "data_path = './faces/user/'\n",
    "onlyfiles =[f for f in listdir(data_path) if isfile(join(data_path,f))]\n",
    "\n",
    "Training_Data,Labels = [],[]\n",
    "\n",
    "for i,files in enumerate(onlyfiles):\n",
    "    image_path = data_path + onlyfiles[i]\n",
    "    images = cv2.imread(image_path,cv2.IMREAD_GRAYSCALE)\n",
    "    Training_Data.append(np.asarray(images,dtype = np.uint8))\n",
    "    Labels.append(i)\n",
    "    \n",
    "Labels = np.asarray(Labels,dtype = np.int32)\n",
    "model = cv2.face.LBPHFaceRecognizer_create()\n",
    "\n",
    "model.train(np.asarray(Training_Data),np.asarray(Labels))\n",
    "print(\"Model Trained Succesfully\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "j6QTvwjIpVGo",
    "outputId": "34c747a7-2dd3-4d4d-ddc7-3b70bc24249f"
   },
   "outputs": [],
   "source": [
    "face_classifier = cv2.CascadeClassifier(\"haarcascade_frontalface_default.xml\")\n",
    "def face_extractor(img, size = 0.5):\n",
    "    gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_classifier.detectMultiScale(gray,1.3,5)\n",
    "    if faces is ():\n",
    "        return img,[]\n",
    "    for (x,y,w,h) in faces:\n",
    "        cv2.rectangle(img,(x,y),(x+w,y+h),(0,255,255),2)\n",
    "        roi = img[y:y+h, x:x+w]\n",
    "        roi = cv2.resize(roi,(200,200))\n",
    "    return img,roi\n",
    "cap = cv2.VideoCapture(0)\n",
    "while True:\n",
    "    ret,frame = cap.read()\n",
    "    image,face = face_extractor(frame)\n",
    "    try:\n",
    "        face = cv2.cvtColor(face,cv2.COLOR_BGR2GRAY)\n",
    "        results = model.predict(face)\n",
    "        if results[1]<500:\n",
    "            confidence = int(100 * (1-(results[1])/400))\n",
    "            display_string = str(confidence) + '% sure this guy is myself'\n",
    "        cv2.putText(image,display_string,(100,120),cv2.FONT_HERSHEY_COMPLEX,1,(255,120,150),2)\n",
    "        if confidence > 75:\n",
    "            cv2.putText(image,\"Unlocked\" ,(250,450),cv2.FONT_HERSHEY_COMPLEX,1,(0,255,0),2)\n",
    "            cv2.imshow(\"Face Recognition\",image)\n",
    "        else:\n",
    "            cv2.putText(image,\"Locked\" ,(250,450),cv2.FONT_HERSHEY_COMPLEX,1,(0,0,255),2)\n",
    "            cv2.imshow(\"Face Recognition\",image)\n",
    "    except:\n",
    "        cv2.putText(image,\"No Face Found\" ,(220,120),cv2.FONT_HERSHEY_COMPLEX,1,(0,0,255),2)\n",
    "        cv2.putText(image,\"Locked\" ,(250,450),cv2.FONT_HERSHEY_COMPLEX,1,(0,0,255),2)\n",
    "        cv2.imshow(\"Face Recognition\",image)\n",
    "    if cv2.waitKey(1) == 13:\n",
    "        cap.release()\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FXcvuNeLpVGo",
    "outputId": "4b52ed70-9629-4d7a-d597-8aaa3b22823c"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4Ry1ePvJpVGo"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iYObKLnwpVGp"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
